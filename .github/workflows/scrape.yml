name: Scrape Sleeper History

# ⬅️ NEU: Schreibrechte für Push
permissions:
  contents: write
  
on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * TUE"  # jeden Dienstag 06:00 UTC (passe an)

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Run scraper
        run: python main.py

       # ⬅️ NEU: Debug – zeigt dir, ob Dateien wirklich da sind / ignoriert werden
      - name: Inspect files
        run: |
          echo "PWD:" && pwd
          echo "Root listing:" && ls -la
          echo "Output listing:" && ls -la output || true
          echo "Git status:" && git status --porcelain=v1

      # ⬅️ NEU: Debug – zeigt .gitignore an
      - name: Show .gitignore
        run: |
          if [ -f .gitignore ]; then
            echo ".gitignore content:" && cat .gitignore
          else
            echo "(no .gitignore)"
          fi

      # ⬅️ Optional aber empfohlen: Artefakt hochladen, damit du die CSVs direkt
      # aus dem Actions-Run herunterladen kannst (auch wenn Push mal nicht klappt)
      - name: Upload output as artifact
        uses: actions/upload-artifact@v4
        with:
          name: sleeper-output
          path: output/**
          if-no-files-found: warn

      # ⬅️ ERSETZT den alten Commit/Push-Step
      - name: Commit & Push CSVs
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          echo "Git status (after add):"
          git status --porcelain=v1
          if [ -n "$(git status --porcelain=v1)" ]; then
            git commit -m "update sleeper CSVs"
            git push
          else
            echo "No changes"
          fi
